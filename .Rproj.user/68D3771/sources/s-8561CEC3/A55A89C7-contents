---
title: "Candidate Management Procedure Developers Guide"
author: "Tom Carruthers (<t.carruthers@fisheries.ubc.ca>)"
date: "`r Sys.Date()`"
output:
  word_document:
    toc: yes
  html_document:
    number_sections: yes
    toc: yes
    toc_float: yes
  rmarkdown::html_vignette:
    number_sections: yes
    toc: yes
  rmarkdown::pdf_vignette:
    number_sections: yes
    toc: yes
  pdf_document:
    toc: yes
subtitle: ICCAT Atlantic Wide Research Programme for Bluefin Tuna (GBYP)
vignette: |
  %\VignetteIndexEntry{ABT-MSE} %\VignetteEngine{knitr::rmarkdown} %\VignetteEncoding{UTF-8}
---

<style type="text/css">

body{ /* Normal  */
   font-size: 12px;
}
td {  /* Table  */
   font-size: 8px;
}
h1 { /* Header 1 */
 font-size: 18px;
 color: DarkBlue;
}
h2 { /* Header 2 */
 font-size: 15px;
 color: DarkBlue;
}
h3 { /* Header 3 */
 font-size: 14px;
 color: DarkBlue;
}
code.r{ /* Code block */
  font-size: 10px;
}
pre { /* Code block */
  font-size: 10px
}
</style>


```{r set options, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
knitr::opts_chunk$set(dpi=85)
options(width = 650)
```

<br>

# Updates of which to be aware for version 6.6.x

## Plotting indices

At the end of an MSE run, the 'true' vulnerable biomass corresponding to each index is stored in addition to the indices that were simulated with error and autocorrelation. These are slots VBi and Iobs and they are 4 dimensional: MP x simulation x index x year. These include historical and future projections (remember year 52 is 2016).

You can plot these slots using the function plot_Indices(MSEobject) or plot_Indices(MSE_example, MPs=c(1,3),index="GOM_LAR_SUV")

## New indices

The latest round of ABT MSE development has greatly increased the number of indices that are available to MPs. After loading the library, you can use loadABT() and look at the new indices by typing 'Indices' into the console. There are now 13 of them. Two important notes: 

* The order in which the indices appear has changed so you'll have to modify any of your previous MPs accordingly
* You are not to use 'CAN ACO SUV' at the request of the data providers until further notice

The OM and MSE objects now have a slot Istats that shows the relevant index statistics as they are simulated for each OM. 

The order in which they are simulated follows the object Indices and the MSE slot Inames

## Setting up deterministic runs

As before, if you would like to create projections that do not have any observation error in their indices, use the operating model with a 'd' on the end (e.g. OM_1d, OM_2d etc) and the 'Perfect_Obs' observation error model. 

New however: if you also want to have deterministic recruitment in your projections you'll have to add the argument Deterministic = T. Ie:

myMSE <- new('MSE', OM=OM_1d, Obs=Perfect_Obs, Deterministic=T)


## Check mode

Running the MSE with check = T:

myMSE <- new('MSE', OM=OM_1d, Obs=Perfect_Obs, check=T)

now shows perfect recreation of M3 dynamics in the ABT-MSE framework. You can also see plots of the expected spatial distribution of catch-at-age by fleet in the final year. 

You will furthermore see the historical recreation of each of the indices available to MPs for future projections. 


# Introduction

The objective of this document is to provide a concise guide to designing, debugging, testing and tuning candidate management procedures (CMPS) using the Atlantic Bluefin Tuna MSE R package. For further information on the operating model structure, conditioning of operating models, data used in conditioning and other features of the R package, readers are referred to the more extensive ABT MSE R package user guide and the Trials Specifications document. 

Atlantic Bluefin tuna are managed by the setting of TACs for the East and West Atlantic areas. The ABT MSE operating model is unique in that it models the mixing of Eastern and Western stocks through these two areas. Consequently management advice for the East impacts both Eastern and Western stocks, and similarly fo the West. This means that there is no way to evaluate a West Area Management Procedure in isolation without also specifying an East Area Management Procedure. Unlike the testing of management procedures elsewhere, Atlantic bluefin tuna MP development must test pairs of CMPs simultaneously, including a CMP for the West area combined with a CMP for the East area. 
 

# Installation

In this installation script I am assuming that your R package installer and other files are stored in a folder 'C:/ABT-MSE/'.

1. Install [R for Windows](https://cran.r-project.org/bin/windows/)
2. Install [RStudio](https://www.rstudio.com/products/rstudio/download/)
3. Install Package dependencies

```{r install_package_depends,eval=F}
source("C:/ABT-MSE/Depends.r") 
```

4. Install the ABTMSE R package by opening RStudio and entering the following code at the R console (making sure to change the file path to reflect where you put the ABT-MSE folder on your computer):
```{r install_package,eval=F}
install.packages("C:/ABT-MSE/ABTMSE_6.6.11.tar.gz") 
```

5. Check that the installation is successful by finding this help file (the ABTMSE vignette):
```{r load_library, eval=T}
library(ABTMSE)
??ABTMSE
```

6. Load all Package data and objects into the current R session:
```{r load_objects, eval=T}
loadABT()
```

If you have any difficulties please send an inquiry including some reproducible code to: t.carruthers@oceans.ubc.ca

<br>

# Ensuring your results are comparable

At a minimum the performance of all CMPs should be presented for reference-case operating models using the 'Umax_90' implementation error model, the 'Good_Obs' observation error model and an interval of 2 years between when TACs are set, i.e:

testCMP<-new('MSE', OM=OM_1, Obs=Good_Obs, MPs=myMPs, interval=2, IE="Umax_90")

The package defaults to these specifications so this is enough:

testCMP<-new('MSE', OM=OM_1, MPs=myMPs)

For deterministic runs without future process (i.e. with deterministic recruitment) and wihtout observation error use: 

testCMP_D<-new('MSE', OM=OM_1, MPs=myMPs, Obs=Perfect_Obs, Deterministic=T)

# Operating models

### Reference Trials

An MSE design object *Design* was also loaded with loadABT(). *Design* is a list of the factors and their levels used in defining the reference set of operating models, e.g. the MSE design outlined in the Trial Specifications document.

Here is a figure showing how the reference OM numbering relates to the five factors (recruitment, abundance, spawning fraction / natural mortality rate M, mixing and weighting of length composition data):

<img src="Ref_OMs.jpg" width="560">


The list item *all_levs* shows all levels that were used in defining the factorial design of the MSE reference operating models:

```{r design_all_levse}
Design$all_levs
```

A text description of these is also available:

```{r design_all_lnams}
Design$all_lnams
```

The full design matrix can be found in the list item *Design_Ref* and is just the factorial combination of these levels:

```{r design_design_ref}
Design$Design_Ref
```

This design grid explains the nomenclature of the various operating models (class OM) and their input definition files (class OMI) which are numbered from 1 to `r nrow(Design$Design_Ref)` corresponding to the rows of this design matrix:

```{r design_list_OMs}
avail('OM')
```

You'll notice that some objects in the ABTMSE package have the extension *\_example* and *\_d*. The example objects are stream-lined objects that are suitable for tutorials and demonstrations which involve less computational overhead (e.g. they require fewer simulations and require less system memory). 

The 'd' objects are deterministic operating models that simply include two simulations only that are identical and fixed to the maximum likelihood values of the operating model fits. These are useful for MP testing since they provide a quick evaluation of MP performance at the most probable combination of operating model parameters. 


### Robustness Trials


Coming in the next version!  


# Selecting CMPs for testing

Specifying CMPs is somewhat more complex in a multi-stock MSE as they can be specific to data from certain areas. For example *DD_MED* may be a delay-difference assessment fitted to a relative abundance index for spawning biomass in the Mediterranean (e.g. a larval survey). 

To specify management procedures in this MSE framework you must select a MP for each spatially distinct area to which an MP is to be applied. For example, an index-based CMP in the West and a Surplus production stock assessment in the East. Traditionally the spatial division for Atlantic bluefin has been at (mainly) 45 degrees W. In this quick start section we are going to ignore MP areas and the package will assume the default setup which is 2 data areas - 2 MPs, one per area, divided by 45deg W.  

A related issue is fleet allocation of regional TACs that are calculated by CMPs (the 2020 allocation is provided by ICCAT and assumed constant into the future - it is an matrix object called 'Allocation' [area x fleet] that is loaded with loadABT()). 

You can search for MPs and find help documentation on these:

```{r qs_MPs}
avail('MP')
?U5
```

For now we're going to select a few premade MPs for a demonstration MSE. 

As mentioned above, CMPs must be chosen in groups, one corresponding to each area for which data are disaggregated. In the default MSE run there are two per management system (a CMP in the East and a CMP in the West). We are going to use a list object to store our pairs of CMPs:


```{r qs_spec_MPs}
myMPs<-list(c('U5','U5'),
          c('MeanC','DD_i4'),
          c('MeanC','MeanC'))

```

This code will test three management systems. One where a fixed harvest rate of 5 percent is used in both the West and the East, a second where mean historical catches are the TAC in the East and a delay-difference model is applied in the West, and a third management system where the TAC is set to mean historical catches in both the West and the East. The principal motivation for choosing these MPs in this tutorial is that they run quickly. 

For now we are going to use one of the prebuilt OMs *OM\_example* that only requires the computation of `r OM_example@nsim` simulations.

# Running an MSE

Management strategy evaluation is computationally intensive and typically requires the recursive application of statistical models (CMPs) for many independent simulations. 

It is a computational problem that is 'embarrasingly parallel' and therefore can make use of the extra horsepower of a modern PC which has multiple threads (typically 4 threads for an i5 Intel CPU and 8 threads for a hyperthreaded i7, although it is not uncommon for contemporary workstations to have 32 or more threads).

To use parallel processing we need to initialize a cluster on your computer:

```{r sfinit}
sfInit(parallel=TRUE, cpus=detectCores()) 

```

To run an MSE it is necessary to specify the:

* operating model, 
* observation error model, 
* CMPs to be tested,
* implementation error model (simulating how well CMP recommended TACs are followed in the simulated fishery) and 
* the interval over which MPs will re-run (how often new TAC advice is calculated). 

In this preliminary run we select the example operating model *OM\_example*, the bad observation error model *Bad_Obs*, our custom MPs above, an update interval of 3 years (ie MPrun1 TAC1, TAC1, TAC1, MPrun2 TAC2, TAC2, TAC2, MPrun3... etc) and an implementation error model that includes catches 10% higher than specified by the CMPs. 

*Note that this will take a few minutes to run*

```{r qs_MSE, eval=F}
MSE_example<-new('MSE',OM=OM_example,Obs=Bad_Obs,MPs=myMPs,interval=3,IE="Overage_10")
```

You may have noticed that while we specified only three management systems (three pairs of East/West MPs) in fact, four were tested and that the first, labelled *ZeroC (East) and ZeroC (West)* we did not specify. 

ZeroC is a reference management procedure that recommends close to zero catches (enough to generate catch data but no catch). 

The purpose of the *ZeroC* MP is to generate performance metrics that evaluate future stock size with reference to the highest simulated biomass achievable. In its current configuration the MSE function will always test this *ZeroC* MP alongside any that you specify. 

# MSE outputs

A very large amount of information has been stored in the MSE object *MSE_example*. A standard performance metrics table can be calculated using the function getperf():

```{r qs_getperf}
getperf(MSE_example)
```

Two tables are produced in a list object, one table for each stock. 

The tables show performance by MP (row) and performance metric (column). Each of these performance metrics is a class PM and has help documentation available to describe it:

```{r qs_help_PMs}
avail('PM')
?C10
?PGK
```

Projection plots can also be produced:

```{r qs_plot_MSE, fig.width=7, fig.height=5.5}
plot(MSE_example)
```

Each row of this plot represents a pair of CMPs (a management system). Projections of catch and SSB are shown in terms of their median (solid black line), 5th and 95th percentiles (the shaded region) and ten individual simulations (the multicolored lines). 

Note that among MPs, each simulation has identical future biological conditions (recruitment, growth etc). In other words a red projected line (a simulation) for one CMP corresponds with the red projected line for the other CMPs. By keeping background simulation conditions the same among CMP runs, the relative performance of CMPs is revealed by many fewer simulations (one CMP cannot outperform another due to sampling a more productive future by chance). 

A principal objective of MSE is to reveal the trade-offs among management objectives. The package includes a standard trade-off plot:

<a id="QS_Tplot"></a>

```{r qs_Tplot_MSE, fig.width=9, fig.height=7}
Tplot(MSE_example)
```

Six performance metrics are plotted:

1. Long Term Yield (mean yield over the final 21-30 projected years)
2. Probability of being in the Green Kobe region ('F<FMSY' and 'B>BMSY') over the entire projection.
3. Probability of being in an overfished state (B<BMSY) over the entire projection
4. Probability of overfishing (F>FMSY) over the entire projection
5. Average Annual Variability in Yield (AAVY) the mean fractional difference in catches among years.
6. Final depletion, the mean spawning stock biomass relative to unfished in the final 21-30 projected years (note that the default definition of 'unfished' biomass in this framework is dynamic SSB0 - the spawning stock biomass obtained were zero catches to have occured in the fishery). 

In the first row, the six metrics are plotted against each other in three panels for the eastern stock. The second row repeats this for the western stock. 

# Designing Management Procedures 

## dset: a standard data format for simulated data

When the MSE runs, in every year that the TAC is updated by a CMP, simulated data are generated. These simulated data are calculated from operating model quantities (e.g. spawning biomass, real simulated catches) subject to autocorrelation and precision defined by the observation error model. These simulated data are used by the CMPs to generate TAC advice. 

There is a standard format for simulated datasets. 

```{r Step_4_dset_example}
 ?dset
```

Two examples were loaded at the start of this session by the loadABT() function. These are 'snapshots' of data that have occured at some point in the forward projection of an MSE using an MP: 

* dset\_example\_East
* dset\_example\_West

These example data sets are helpful for designing and testing your own CMPs. 

Additionally every time an MSE is run, the simulated dataset in current use is passed to the global environment (called *dset*). It follows that if the MSE function crashes due to an error in a CMP, it is easier to test the CMP again using the offending simulated data and debug the problem (note that the dset you see if the MSE crashes is a list object so dset[[1]] is the equivalent of dset\_example\_East, for example.  

## Visualizing simulated indices

Plots of the various indices can also be produced from the MSE object slots VBi (true simulated vulnerable biomass) and Iobs (vulnerable biomass subject to error and autocorrelation):

```{r plotIndices, fig.width=7, fig.height=5.5}
plot_Indices(MSE_example,index="GOM_LAR_SUV")
```

## Anatomy of an MP

Management Procedures (object class *MP*) can vary greatly in their complexity ranging from a constant catch MP to an MP that uses data-filtering algorithms linked to stock assessments coupled to harvest control rules. 

However, all CMPs have the same basic inputs/outputs: they operate on a simulation number *x* of a simulated dataset object *dset* and return a single TAC recommendation. 

Lets look at a relatively simple CMP, Islope1 which can have variants depending on which index you want to use (below is the example that uses index number 3):

```{r Step_4_MP_anatomy}
 avail('MP')
 ?Islope1_i4
 Islope1
 Islope1_i4
```

*Islope1* creates a reference catch level *TACstar* based on historical catch levels and an adjustment factor "xx". The MP then makes TAC recommendations with the aim of keeping a constant index level.

Probably the easiest way to understand how an MP works is to design your own. 

## Designing and testing a simple average catch MP

Here we will create a new CMP and make it compatible with the ABT-MSE framework. Lets start off simple and design a CMP that sets TACs according to historical average catches. 

Simulated data objects *dset* have a slot for observed historical catches that is labelled *Cobs*. Lets examine one of the examples:

```{r Step_4_muC_start}
 dim(dset_example_East$Cobs)

```

This is a matrix with nsim rows and nyear columns. We have to design an MP that will, for any simulation number x, return the mean historical catch. In R this is very terse:

```{r Step_4_MeanC}
 MeanC<-function(x,dset) mean(dset$Cobs[x,])
 class(MeanC)<-"MP"
```

The first argument of a CMP function must be the simulation number *x*. The second argument must be the simulated dataset *dset*. This ensures that the CMP is compatible with parallel processing using the *sfSapply()* function. 

Also required is that the CMP returns a single numeric value that is the TAC recommendation, in this case the mean historical catch level for that simulation *x*. 

In the second line of code we assign a class of *MP* to our new *MeanC* management procedure. It is important to do this for your CMP because it allows users to search for MPs. 

Now we can test our CMP using some example data. The simplest way is to pick a simulation number in this case the 1st simulation:

```{r Step_4_MeanC_test1}
 MeanC(x=1,dset=dset_example_East)
```

Lets make sure this works for all simulations using the regular *sapply()* function:

```{r Step_4_MeanC_test2}
 nsim<-nrow(dset_example_West$Cobs)
 sapply(1:nsim,MeanC,dset_example_East)
```

Lastly you could make sure that the MP works in parallel (there are no functions or objects that the cluster can't see):

```{r Step_4_MeanC_test3}
 sfInit(parallel=T,cpus=detectCores())
 sfSapply(1:nsim,MeanC,dset_example_East)
```

Note that for simple CMPs like this, parallel processing isn't necessary and might even be a bit slower due to the overhead of sending data to the cluster. However for more complex MPs that involve estimation phases, parallel processing can speed up the analysis by a large margin (typically running in 1/(0.8*nthreads) of the time). 

*For large MSE analyses with many simulations and CMPs, very large clusters can be used with as many as 1000 threads*


### Designing a somewhat more complex surplus production MP

Many CMPs use numerical optimization to fit models to data. A good example are stock assessments such as surplus production models that are used to provide management advice for many Atlantic tuna and billfish species, for example BSP (McAllister et al. ) and ASPIC. 

Here we design a relatively simple three parameter, observation error only, surplus production model. The new SP MP requires two functions: 

1. The MP function (data in, TAC out)
2. The estimation model (that is used inside the MP function to find parameters that lead to the best fit to historical data)

Similarly to many CMPs, this surplus production requires an index of abundance. This means that the MP will be specific to a particular assessment area and 'stock'. 

In this case we are going to create a CMP for the Western Stock using the GOM_LAR_SUV index. Remember these indices are stored in the @MPind slot of the observation model:

```{r Step_4_Examine indices}

unique(Bad_Obs@MPind$Name)
Indices

```

Here is a CMP function that processes the data and has a couple of extra bells and whistles for evaluating model fit, diagnosing convergence and also initiating the model at a given depletion level:

```{r Step_4_SP_def}

SP_i4<-function(x,dset,startD=0.5,checkfit=F){                  # a very simple surplus production model, r, K and q leading
  
  nyears<-dim(dset$Iobs)[3]               # get the number of years of data (the 3rd dimension of Iobs)
  Ind<-dset$Iobs[x,4,1:nyears]            # get the index
  yind<-(1:nyears)[!is.na(Ind)]           # find the years where the index is available (ie not NA)
  
  C_hist <- dset$Cobs[x,yind]             # store catches for this time period
  E_hist <- C_hist/Ind[yind]              # store standardized effort (partial F)
  E_hist <- E_hist/mean(E_hist)           # normalize the effort to mean 1
  E_hist[is.na(E_hist)]<-E_hist[(1:length(E_hist))[match(TRUE,!is.na(E_hist))]] # Impute missing effort
 
  surv<-exp(-cumsum(dset$M[x,]))          # survival at age
  muM<-sum(dset$M[x,]*surv)/sum(surv)     # mean natural mortality rate accounting for survival
  ny <- length(C_hist)                    # record the total number of years of data
  params<-c(muM,sum(C_hist),0.05)         # initial values for r, K and q (Effort covariate has been standardized to mean 1) 
  rprior<-c(muM,0.5)                      # a vague prior on r based on the assumption that FMSY ~ 0.5 x M and FMSY = r/2
  
  opt<-optim(log(params),SP_R,opty=1,
             C_hist=C_hist,E_hist=E_hist,
             rprior=rprior,ny=ny, # run an optimization to fit the data
             startD=startD,                # starting depletion according to function argument above
             method = "L-BFGS-B", 
             lower=log(params/c(3,20,20)), # the first parameter, r, is bounded more tightly as K and q
             upper=log(params*c(3,20,20)), # the greater constraint on r is to prevent chaotic model behavior above 1.3
             hessian = TRUE,               # return a hessian matrix for simple testing of convergence
             control=list(maxit=100))      # optimization can't run for more than 100 iterations

  posdef<-sum(eigen(solve(opt$hessian))$values>0)==3 # is the hessian positive-definite, ie has convergence been achieved?
  
  if(checkfit){                            # Plot fit to catches for model testing
    fit<-SP_R(opt$par,opty=4,C_hist=C_hist,E_hist=E_hist,rprior=rprior,ny=ny,startD=startD); 
    plot(fit[,1],xlab='Model year',ylab="Catches",col='blue',ylim=c(0,max(fit)))
    lines(fit[,2],col='red') 
    legend('topright',legend=c("Observed","Predicted"),text.col=c("blue","red"),bty='n')
    legend('topleft',legend=paste0("Converged: ",posdef),bty='n')
  }

  if(posdef){   # if model converged return new TAC
    SP_R(opt$par,opty=2,C_hist=C_hist,E_hist=E_hist,rprior=rprior,ny=ny,startD=startD)  # opty = 2 returns FMSY x cur biomass
  }else{         # otherwise return previous TAC subject to a 5 percent downward adjustment
    dset$MPrec[x]*0.95
  }  
}
  
class(SP_i4)<-'MP'

```

The corresponding SP estimation function is: 

```{r Step_4_SP_R_Def}

SP_R<-function(logparams, opty, C_hist, E_hist, rprior,ny,startD){   # simple surplus production model r, K and q leading
  
  r<-exp(logparams[1])                                # Intrinsic rate of increase
  K<-exp(logparams[2])                                # Carrying capacity
  qq<-exp(logparams[3])                               # Catchability (F=qE)
  B<-K*startD                                         # Starting biomass level
  
  Cpred<-rep(NA,ny)                                   # A predicted catch vector
  Bpred<-rep(NA,ny)                                   # A predicted biomass vector
  
  for(i in 1:ny){                                     # loop over years
    Cpred[i]<-B*(1-exp(-qq*E_hist[i]))                # Predicted catches
    B<-B+r*B*(1-B/K)-Cpred[i]                         # update biomass according to SP dynamics
    Bpred[i]<-B                                       # Record biomass
  }
 
  if(opty==1){                                         # return objective function
    
    test<-dnorm(log(Cpred+1E-10),log(C_hist+1E-10),0.2,log=T)      # observed versus predicted log catches
    #test<-dnorm(Cpred,C_hist,0.2*Cpred,log=T)         # observed versus predicted catches
    test2<-dlnorm(r,log(rprior[1]),rprior[2],log=T)    # a weak  lognormal prior on r
    test[is.na(test)|test==(-Inf)]<--1000              # some robustification
    if(is.na(test2)|test2==-Inf|test2==Inf)test2<-1000 # some more robustification
    return(-sum(test,test2))                           # objective function
    
  }else if(opty==2){                                   # return MLE FMSY * current biomass estimate
    
    r/2*Bpred[ny]
    
  }else if(opty==3){
    
    B[ny]/K                                            # return depletion
  
  }else{
    
    cbind(C_hist,Cpred)                                # return observations vs predictions
    
  }

}

```

As before we can now test this on an example dataset:

```{r Step_4_SP_test1a}
 SP_i4(x=1,dset=dset_example_West)
 SP_i4(x=1,dset=dset_example_West,startD=0.5)
 
```

Checking the fit to observed catches:

```{r Step_4_SP_test1b,fig.width=4,fig.height=4}
 SP_i4(x=1,dset=dset_example_West,checkfit=T)
```

Lets make sure this works for all simulations using the regular *sapply()* function:

```{r Step_4_SP_test2,error = TRUE}
 nsim<-nrow(dset_example_West$Cobs)
 sapply(1:nsim,SP_i4,dset_example_West)
```

Will the MP work in parallel?:

```{r Step_4_SP_test3a,error = TRUE}
 sfInit(parallel=T,cpus=detectCores())
 sfSapply(1:nsim,SP_i4,dset_example_West)
```

You can see that there is an error. 

The only issue with our new CMP is that it requires the estimation function *SP_R* and this is not visible to the cluster so can't currently be used in parallel processing.

This however is easily solved with the *sfExport()* function. The correct order of operations is:

```{r Step_4_SP_test3b}
 sfInit(parallel=T,cpus=detectCores())
 sfExport("SP_R")
 sfSapply(1:nsim,SP_i4,dset_example_West)
```

You may have noticed this is faster than the non parallel version by some margin:

```{r Step_4_SP_test3c}
 system.time(sapply(1:nsim,SP_i4,dset_example_West))
 system.time(sfSapply(1:nsim,SP_i4,dset_example_West))

```

The more computationally intensive the CMP, the wider the performance margin between parallel and regular linear processing. It is for this reason that it may be worth going the extra step to make your CMP compatible with cluster computing by exporting any internal functions to the cluster. 

## Example of designing an index-based MP for Atlantic Bluefin tuna 

This document is intended for users who wish to design and test a CMP that sets annual TACs for the East and West management areas using only indices of abundance. This is a critical step in the MSE process for ABFT - do not hesitate to contact Tom Carruthers (t.carruthers@oceans.ubc.ca) for help with CMP development.  

In this example we are going to specify a very simple target index CMP, a CMP that will seek a target level by modifying TACs. 

There are a number of possible ways to do this but we will use a very basic incremental TAC stepping method.

We need to know a few things including 1) the target level of the relevant index, and 2) the maximum rate of TAC change which we are willing to tolerate.

We can see the names of the various indices available for CMP development by looking at the table object *Indices* that was loaded when your ran the line loadABT(). 

```{r MPdev1}
Indices

```
You will notice that each index is collected in an area associated with a current stock assessment where Stock = 1 is the East-area and Stock = 2 is the West area. 

Let's say we wished to use the Mediterranean Larval Survey (Index No. 2) to set TACs in the East and the Gulf of Mexico Larval Survey (Index No. 4) to set TACs in the West. 

Let's assume that the current stock level (over the last three years) is around 1.5 times the MSY level in the East ([Figure 4 for base reference operating model 1AI of this document](https://drive.google.com/open?id=1oJmXDD6tRKbEI4DwZnsLbFIAcq1EfiPt)) and around 0.5 times the MSY level in the West. 

We can extract the current index levels (years 2014 to 2016 are years 50 to 52 since model starts in 1965) for each index from the observation model slot MPind that includes all the index data:

```{r MPdev2}
MPind<-Bad_Obs@MPind
IndE<-MPind[MPind$No==2 & MPind$Year%in%(50:52),] # get the Med Larval Survey
IndW<-MPind[MPind$No==4 & MPind$Year%in%(50:52),] # get the GOM Larval Survey

```

It is now straightforward to determine a possible target level for each index:
```{r MPdev3}

TargE=mean(IndE$Index)/1.5
TargW=mean(IndW$Index)/0.5
paste("TargE =",TargE)
paste("TargW =",TargW)

```

In this simple example, the two index based MPs will alter the current TAC according to the ratio of current index levels (the observed index over the last *yrs4mean* number of years (default is 4 years) to target levels. We will set the maximum extent of TAC change (Delta) to 15% for both MPs.

```{r MPdevE}
MP_E = function(x,dset,Targ=22.56,Deltaup=0.05,Deltadown=0.20,IndexNo=2,yrs4mean=3){

  lastyr = dim(dset$Iobs)[3]                # Most recent year
  datayrs = lastyr-(yrs4mean-1):0           # Position of data for calculating current index
  curI = mean(dset$Iobs[x,IndexNo,datayrs],na.rm=T) # mean of last yrs4mean years
  Irat = curI/Targ                          # Index ratio
  oldTAC = dset$MPrec[x]                    # The last TAC recommendation

  if(Irat<(1-Deltadown)){                       # If index ratio is less than minimum adjustment
    TAC = oldTAC*(1-Deltadown)

  }else if(Irat>(1+Deltaup)){                 # If index ratio is greater than maximum adjustment
    TAC = oldTAC*(1+Deltaup)

  }else{
    TAC = oldTAC*Irat
  }

  TAC                                       # Last thing returned is the TAC recommendation

}

class(MP_E) = "MP"                         # Finally make sure it is of class MP

```


The West CMP is different only in the first line of function where we have to set an appropriate target level and index number:


```{r MPdevW}
MP_W = function(x,dset,Targ=0.42,Deltaup=0.05,Deltadown=0.20,IndexNo=4,yrs4mean=3){

  lastyr = dim(dset$Iobs)[3]                # Most recent year
  datayrs = lastyr-(yrs4mean-1):0           # Position of data for calculating current index
  curI = mean(dset$Iobs[x,IndexNo,datayrs],na.rm=T) # mean of last four years
  Irat = curI/Targ                          # Index ratio
  oldTAC = dset$MPrec[x]                    # The last TAC recommendation

  if(Irat<(1-Deltadown)){                       # If index ratio is less than minimum adjustment
    TAC = oldTAC*(1-Deltadown)

  }else if(Irat>(1+Deltaup)){                 # If index ratio is greater than maximum adjustment
    TAC = oldTAC*(1+Deltaup)

  }else{
    TAC = oldTAC*Irat
  }

  TAC                                       # Last thing returned is the TAC recommendation

}

class(MP_W) = "MP"                         # Finally make sure it is of class MP

```

We can now test out our new CMPs against simple mean catches and a fixed harvest rate of 5% (U5):

```{r MPtester,eval=F}

myMPs<-list(c('U5','U5'),
            c('MeanC','MeanC'),
            c('MP_E','MP_W'))

myMSE2<-new('MSE',OM=OM_1,Obs=Bad_Obs,MPs=myMPs,interval=5,IE="Umax_90")
plot(myMSE2)
getperf(myMSE2)

```

A standard MSE performance trade-off plot PPlot() is also available that defaults to the 7 performance metrics (class PM) of the trial specifications document. 

You can find out more about these PMs using the avail() function and also use PPlot() to produce a performance plot for a smaller number of PMs (or your own custom PMs) if you would prefer:

```{r PPlot,fig.width=8, fig.height=10}

PPlot(MSE_example)
avail('PM')
?C10
?PPlot

```



## One last example of a CMP specification, from start to finish

In just one block of code lets design and test a CMP that uses the spawning index in the East to inform stock depletion. 

Assuming surplus production dynamics, this means that FMSY x current biomass is simply depletion x MSY x 2. Lets assume average catches are approximately MSY to complete this MP:

```{r Step_4_MCD_i2}

MCD_i2<-function(x,dset,startD=0.5){
  
  nyears<-dim(dset$Iobs)[3]                  # Most recent year
  mean(dset$Cobs[x,],na.rm=T)*               # Average historical catches
    mean(dset$Iobs[x,5,(nyears-2):nyears]/max(dset$Iobs[x,2,],na.rm=T))*   # Mean index over last three years
    2*startD                                 # Adjusted for starting depletion and MSY production at depletion = 0.5
  
}

class(MCD_i2)<-"MP"

sfSapply(1:nsim,MCD_i2,dset_example_East)  

```


## Tips for MPs

* It is generally a good idea to take measures to ensure your MPs are as robust as possible. For example when taking average catches it could be a good idea to ignore 'NA' values - setting the argument *na.rm* in our mean catch MP:

```{r robust1}

 MeanC<-function(x,dset) mean(dset$Cobs[x,],na.rm=T)

```

* If estimating parameters inside the model, it is best to initialize on the side of low exploitation. For example, initalized at high intrinsic rate of increase (r), low catchability (q) and a carrying capacity (K) twice that of the sum of historical catches, the surplus production CMP we defined above avoids a crashed stock in the first instance (which could lead to very flat gradients in the objective function with respect to the parameters preventing numerical estimation). 

* If your CMP relies on estimation or 'a good fit' before it produces a TAC recommendation, design it so that there is a diagnostic and an alternative TAC recommendation if this requirement is not met (e.g. our convergence diagnostic in the surplus production custom CMP above).

* Remember that the data can include *NA* values. For example, most of the indices do not go back all the way to the start of the historical simulation. It follows that your CMPs may produce errors if they are not written to extract the parts of the simulated data that are not *NA*. 


## Standardized MSE reporting

New to version 3+ is a standardized MSE report which you can generate for any MSE object

```{r MSE_report,eval=F}

MSE_report(MSE_example,dir="C:/temp", Author='Tom C', introtext="Just a demonstration report", filenam="Example_MSE_report")

```

Author, introtext and filenam arguments are optional. If dir is not specified then the report is created in the current working directory getwd(). 

# Rapid MSE for designing CMPs

The ABTMSE package includes deterministic versions of reference operating models (e.g. OM_1d is the deterministic version of OM_1). These include only two simulations that are identical copies of the maximum posterior density estimates of the fitted operating model. 

Using the 'avail' function you can list the various OMs and get rapid results for the deterministic version of OM #1.


```{r OMd_demo}

avail('OM')
myMPs<-list( c('MP_E','MP_W') )
testCMP<-new('MSE',OM=OM_1d,MPs=myMPs,interval=5,IE="Umax_90", Deterministic=T)
plot(testCMP)

```


By default, the MSE above ran using the 'Good_Obs' observation error model that includes differing scenarios for observation error in future years between the two simulations. If you wish to test MPs with very little observation error, producing almost identical future simulated conditions, then you need to specify the 'perfect' observation error model:

```{r OMd_demo_perfinfo}

avail('Obs')
testCMP2<-new('MSE',OM=OM_1d,Obs=Perfect_Obs,MPs=myMPs,interval=5,IE="Umax_90", Deterministic=T)
plot(testCMP2)

```

You will notice that there is now no difference between the two simulations as observation error is essentially zero and does not lead to diverging projections. 

# Tuning

Coming soon.


# Recap

To recap we needed five lines of code to write, run and read our fitted operating model and then complete and visualize an MSE run:

  * M3write(OMI,M3dir)
  * M3run(M3dir)
  * myOM<-new('OM',M3dir)
  * myMSE<-new('MSE',myOM,Bad\_Obs,MPs=list(c("U5","U5"),c("SP\_i2","MCD\_i5")))
  * getperf(myMSE)
  * plot(myMSE)
  * MSE_report(myMSE,dir="C:/temp", Author='Tom C', filenam="myMSE_report")

<br>



```{r, echo=FALSE, eval=FALSE}
sfStop()                            
```





